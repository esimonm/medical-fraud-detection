{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference to filename with metrics to visualize\n",
    "metrics_file_name = \"sample_TRAIN_mil.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_path = \"../results/metrics/{}\".format(metrics_file_name)\n",
    "metrics = pickle.load(open(metrics_path, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(metrics['train']['losses'], label='Train loss')\n",
    "plt.plot(metrics['valid']['losses'], label='Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics_name = \"20220914-131045_TEST_mil.pkl\"\n",
    "\n",
    "test_metrics_path = \"../results/metrics/{}\".format(test_metrics_name)\n",
    "test_metrics = pickle.load(open(test_metrics_path, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_mat = test_metrics['test']['con_mats']\n",
    "f1_score = 2*con_mat['tp'] / (2*con_mat['tp'] + con_mat['fp'] + con_mat['fn'])\n",
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = con_mat['tp'] / (con_mat['tp'] + con_mat['fp'])\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_mat = test_metrics['test']['con_mats']\n",
    "\n",
    "con_mat_np = np.array([[con_mat['tp'], con_mat['fn']], [con_mat['fp'],con_mat['tn']]])\n",
    "\n",
    "disp = ConfusionMatrixDisplay(con_mat_np, display_labels=[\"Fraud\", \"Not Fraud\"])\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_performance(metrics_names):\n",
    "    fig, axs = plt.subplots(3,2,figsize=(15,20))\n",
    "    metrics = [None for i in range(len(metrics_names))]\n",
    "    for i in range(len(metrics_names)):\n",
    "        metrics_path = \"../results/metrics/{}\".format(metrics_names[i])\n",
    "        metrics[i] = pickle.load(open(metrics_path, \"rb\"))\n",
    "        axs[0,0].plot(metrics[i]['train']['losses'], label='train_loss_'+metrics_names[i])\n",
    "        axs[0,0].plot(metrics[i]['valid']['losses'], label='valid_loss_'+metrics_names[i])\n",
    "        axs[0,1].plot(metrics[i]['train']['accuracies'], label='train_accuracy_'+metrics_names[i])\n",
    "        axs[0,1].plot(metrics[i]['valid']['accuracies'], label='valid_accuracy_'+metrics_names[i])\n",
    "        axs[1,0].plot(metrics[i]['train']['TPRs'], label='train_TPR_'+metrics_names[i])\n",
    "        axs[1,0].plot(metrics[i]['valid']['TPRs'], label='valid_TPR_'+metrics_names[i])\n",
    "        axs[1,1].plot(metrics[i]['train']['FPRs'], label='train_FPR_'+metrics_names[i])\n",
    "        axs[1,1].plot(metrics[i]['valid']['FPRs'], label='valid_FPR_'+metrics_names[i])\n",
    "        axs[2,0].plot(metrics[i]['train']['f1_scores'], label='train_f1_'+metrics_names[i])\n",
    "        axs[2,0].plot(metrics[i]['valid']['f1_scores'], label='valid_f1_'+metrics_names[i])\n",
    "    axs[0,0].legend()\n",
    "    axs[0,1].legend()\n",
    "    axs[1,0].legend()\n",
    "    axs[1,1].legend()\n",
    "    axs[2,0].legend()\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_compare = [\n",
    "    '20220914-131045_TRAIN_mil.pkl'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_performance(models_to_compare)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('fraud_detection')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "493e1a158253a5053f1b979a540e509c0b37ed4535723bc7f169c9fa87d70ae6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
